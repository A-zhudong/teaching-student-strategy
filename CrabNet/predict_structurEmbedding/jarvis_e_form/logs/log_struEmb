nohup: ignoring input
Property "jarvis_e_form" selected for training
model_name:  jarvis_e_form_struPred

Model architecture: out_dims, d_model, N, heads
256, 512, 3, 4
Running on compute device: cuda:0
Model size: 12381700 parameters

Generating EDM:   0%|          | 0/28635 [00:00<?, ?formulae/s]Generating EDM:  31%|███       | 8766/28635 [00:00<00:00, 87652.35formulae/s]Generating EDM:  70%|██████▉   | 19952/28635 [00:00<00:00, 101884.97formulae/s]Generating EDM: 100%|██████████| 28635/28635 [00:00<00:00, 102943.17formulae/s]
loading data with up to 7 elements in the formula
training with batchsize 512 (2**9.000)
Generating EDM:   0%|          | 0/3182 [00:00<?, ?formulae/s]Generating EDM: 100%|██████████| 3182/3182 [00:00<00:00, 133110.01formulae/s]
loading data with up to 7 elements in the formula
stepping every 56 training passes, cycling lr every 1 epochs
checkin at 2 epochs to match lr scheduler
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6714, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7016, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5951, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5847, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5727, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5635, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4976, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4796, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5074, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4573, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4755, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5065, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4577, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4729, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4496, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 0/300 --- train mae: 0.794 val mae: 0.78
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4539, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4999, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4945, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4928, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4566, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4574, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4795, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4660, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4143, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4928, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5215, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5602, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5159, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4698, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4859, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4399, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4351, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4505, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5073, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4705, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5039, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 1/300 --- train mae: 0.791 val mae: 0.778
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4582, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5019, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5076, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4915, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4596, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4506, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5048, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5050, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4666, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4945, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4544, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4949, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4651, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4999, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5104, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4636, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4725, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4576, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4884, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4513, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4165, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5278, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5020, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4714, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4807, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4553, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4730, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4128, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4067, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5016, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4925, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5013, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4912, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4647, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4027, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5072, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4240, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4460, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 3/300 --- train mae: 0.792 val mae: 0.779
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4064, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5039, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4994, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4687, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4566, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4999, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4544, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4986, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4615, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4620, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4991, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4713, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4796, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5018, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4092, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4458, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5076, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4225, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4503, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4415, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4967, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4648, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4452, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4432, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4123, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4517, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4408, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4315, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5113, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5117, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4774, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4884, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4917, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4392, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4843, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4651, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5015, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 5/300 --- train mae: 0.793 val mae: 0.779
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4041, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4025, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4601, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4985, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5024, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4759, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4606, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4755, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4674, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5075, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5418, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5152, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4470, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4615, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4312, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4482, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4460, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4630, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4419, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5151, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4431, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4596, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4512, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4699, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5054, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4303, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4457, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4662, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5255, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4216, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4755, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4546, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 7/300 --- train mae: 0.794 val mae: 0.78
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4482, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5104, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4776, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4588, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4966, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4651, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4861, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4552, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4370, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4588, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4482, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4989, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5643, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4208, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5231, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4642, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4056, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4288, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4608, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4445, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5266, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4674, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4385, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4918, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4166, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4916, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4776, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4070, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 9/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4884, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4551, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4709, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5057, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4655, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4899, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4041, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4813, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4482, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4765, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5223, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5505, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4780, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4601, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4470, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4148, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4058, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4584, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3945, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4460, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4272, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4953, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4907, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4374, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4654, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4138, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4671, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4733, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5080, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4473, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5363, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4483, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4710, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5082, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5100, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4170, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5082, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 11/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4743, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4915, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4630, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4729, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4550, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4596, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4508, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5077, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4776, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4655, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4996, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4175, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4138, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5184, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4481, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4255, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4789, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4316, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5420, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4569, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5132, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5107, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4630, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4583, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4461, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4613, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4404, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5012, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5277, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4292, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4487, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5379, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3924, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4348, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4895, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4526, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5158, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 13/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4636, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4629, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3993, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4620, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5042, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4765, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4064, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4716, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4802, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4782, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4659, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4242, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4582, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4503, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4667, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5205, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4545, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4191, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4599, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4594, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4580, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5207, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4700, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4451, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4623, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5014, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4662, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4474, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4178, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4620, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4558, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4729, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4409, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4245, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5012, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4445, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 15/300 --- train mae: 0.797 val mae: 0.783
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4819, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4790, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4768, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4856, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4608, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4770, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5854, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4949, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4682, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4545, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4768, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4882, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4578, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4772, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4957, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4765, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5083, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4471, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4546, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4543, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4954, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4850, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4597, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5370, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4398, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4505, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5176, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4410, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4318, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4420, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4586, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4731, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4853, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5359, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4205, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4175, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4768, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4406, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5134, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4436, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4550, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 17/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4576, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4031, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5089, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4716, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4640, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4857, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5021, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4543, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4714, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5037, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4618, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3984, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4429, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4711, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5316, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4513, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4707, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4383, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4772, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4181, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4473, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4665, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4707, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4540, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4623, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4899, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5163, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4105, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4987, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4540, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4647, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4846, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4208, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4374, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4544, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 19/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5031, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5039, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4922, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3964, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4818, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4770, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4662, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4109, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5099, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4570, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4394, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5066, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4262, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5090, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4865, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5065, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4228, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4661, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4995, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5204, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4411, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4539, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4843, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4834, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4082, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4578, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4592, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5435, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5079, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4915, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4925, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4508, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4961, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4815, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4415, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4716, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 21/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5081, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4917, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4755, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4604, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4776, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4503, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4713, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4925, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4642, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4710, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5165, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4442, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4195, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4699, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4310, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4679, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5259, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4996, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4659, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5010, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4836, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4883, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4286, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4179, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4592, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4693, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5017, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4348, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4514, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4569, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4861, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4439, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4648, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4686, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4253, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5083, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 23/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4717, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4874, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4586, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5110, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4966, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5588, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4787, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4923, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4647, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4882, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4174, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4159, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4759, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4408, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4778, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4214, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4370, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4635, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4162, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5097, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4178, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5122, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4553, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4470, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4640, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4640, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4770, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4800, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5015, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4410, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5040, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4994, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4185, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4816, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4802, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4586, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 25/300 --- train mae: 0.797 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4491, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4115, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4736, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4973, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4824, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4671, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4774, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4912, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4602, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5050, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5108, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4682, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4729, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4458, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4883, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4636, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4657, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4440, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5285, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5070, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5344, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5139, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4569, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4274, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5099, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4661, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4132, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4212, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5080, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4267, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4867, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4711, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4182, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4146, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4398, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4483, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5174, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4380, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4920, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4358, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5141, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4382, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5220, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4488, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4454, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4592, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 27/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4445, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4707, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4714, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4606, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4984, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4755, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4954, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4594, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5018, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5097, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4660, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4590, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4964, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5109, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4836, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4604, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4674, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4813, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5232, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5140, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4853, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4550, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4539, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4573, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4541, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4540, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4639, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5049, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4413, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4211, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4881, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4674, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4444, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4967, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5175, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5211, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4105, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4816, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4573, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4588, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 29/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4866, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4686, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4787, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4730, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4654, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3990, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4687, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4676, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3935, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4834, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4602, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4818, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5230, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4747, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4443, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5023, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4709, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4422, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5178, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4080, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4843, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4584, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4998, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4879, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4492, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4984, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4491, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4412, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4943, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4341, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4498, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4790, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4508, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 31/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5017, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4630, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4035, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4615, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4949, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4573, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4725, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4613, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4639, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4956, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4513, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4129, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4766, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4956, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4458, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5044, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4230, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4575, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4325, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5171, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4657, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4861, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4283, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4522, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4377, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4945, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4736, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4410, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4403, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4623, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5227, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 33/300 --- train mae: 0.794 val mae: 0.78
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4047, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4676, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4660, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4732, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4711, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4765, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4923, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4551, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4893, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4566, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4598, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4596, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4995, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4976, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4983, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4806, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5096, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4583, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4432, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4157, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4540, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4307, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4398, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4958, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4519, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4653, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4854, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4770, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4377, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4484, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4642, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 35/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4716, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5049, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4834, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4798, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4956, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5075, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4733, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4630, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4567, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4780, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4975, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4260, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4774, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5171, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4893, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4547, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4869, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4177, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4214, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4601, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4837, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5377, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4636, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4405, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4207, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4473, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4945, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4541, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4352, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4444, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5235, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5014, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4274, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4451, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4525, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4618, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4457, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4839, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4357, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4996, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5146, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5228, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5139, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4407, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 37/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4874, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4989, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4551, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5079, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5039, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4666, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5095, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4857, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4818, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4717, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4973, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4213, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4636, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5302, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4374, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4438, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4679, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4798, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4659, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4316, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4982, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4995, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5029, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4421, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4488, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4861, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4287, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4320, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5475, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4644, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4615, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5370, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4407, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4141, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4434, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4462, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4547, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 39/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4920, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4028, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4837, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4723, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4940, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4943, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4953, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4859, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4543, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4859, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4710, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4800, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4879, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4977, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5111, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5103, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5136, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5047, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4647, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4005, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4432, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4865, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5236, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4570, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4390, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4469, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4912, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5286, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4290, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4743, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4361, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4135, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4618, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4241, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4357, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5129, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4417, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4391, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4330, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4419, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 41/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5042, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4790, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4920, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4075, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4809, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4038, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4606, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4777, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5104, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4838, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4543, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4087, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4498, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4475, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4782, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4491, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5050, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4817, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4463, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4568, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4709, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4521, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4644, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4731, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4605, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4666, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5098, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4761, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4550, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4504, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5227, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4676, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4499, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4498, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 43/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4545, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4802, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4711, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4671, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4819, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4651, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4754, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4790, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4297, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4280, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5019, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4543, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4452, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4517, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5313, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4670, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4648, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5074, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4736, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4372, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4521, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4577, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5130, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4436, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4429, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4916, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4461, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4421, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4596, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4653, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4778, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5274, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4124, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 45/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4725, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5068, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4591, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4997, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4008, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4856, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4074, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5068, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4284, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4457, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4922, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4406, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5095, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4407, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4438, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4501, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4407, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4698, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4412, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4606, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4395, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4654, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4772, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5286, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4562, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4642, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4232, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4292, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4440, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4688, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5296, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4813, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5037, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4859, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4688, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4308, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5335, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4975, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4378, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4997, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 47/300 --- train mae: 0.796 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4953, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4800, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4789, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4798, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5023, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4807, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4699, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4553, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4580, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5101, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4432, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4927, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4834, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4553, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4473, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4397, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5159, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5107, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4796, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4423, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5054, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4686, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4567, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4553, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4203, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4526, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5181, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5202, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4566, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4800, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4204, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4605, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4225, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4475, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4402, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4556, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4686, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5215, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4205, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4710, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4608, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4618, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4577, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4579, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4780, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3756, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5130, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4937, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 49/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4090, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4714, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4731, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4686, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4736, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4730, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5011, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4989, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4964, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4858, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4731, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4496, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4881, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4465, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5475, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5106, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4953, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4465, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4854, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4520, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4412, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4843, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5249, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4293, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4709, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4098, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4602, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4431, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5159, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4860, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4618, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4662, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4893, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4547, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5374, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4311, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4480, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4672, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4431, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 51/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4696, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4444, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5011, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4640, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5104, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4081, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4693, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4856, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4732, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4617, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4685, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4819, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4387, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4274, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4615, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4394, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4488, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4557, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5348, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4927, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4725, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5069, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5327, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4458, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4391, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4620, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4578, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4961, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4740, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4943, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4658, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4503, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4047, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4374, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4652, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4206, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4427, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4853, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5375, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4459, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4213, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4266, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4734, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 53/300 --- train mae: 0.797 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5002, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5007, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5011, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4574, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4578, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5106, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4781, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3974, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5090, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4114, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4602, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4730, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4341, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5013, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4495, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4403, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4693, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4620, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4569, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4433, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4660, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4575, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4083, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5261, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5314, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4486, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4977, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4655, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4402, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4652, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4353, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4325, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4372, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4580, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4070, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4990, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4541, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4499, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4347, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4111, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5070, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5052, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4463, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4858, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4968, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4741, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 55/300 --- train mae: 0.794 val mae: 0.78
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5019, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4582, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4780, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4727, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4904, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4063, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4899, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4790, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5010, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5014, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4717, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4415, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4798, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4072, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5010, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4236, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4614, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4535, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4419, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5253, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4294, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4838, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5031, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4400, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4837, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4743, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4593, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4699, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4330, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5083, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4698, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4577, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4705, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5094, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4086, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4594, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4571, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4170, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4916, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 57/300 --- train mae: 0.796 val mae: 0.782
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4616, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4647, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4915, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4752, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4764, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4786, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5073, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4949, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4094, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4646, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4954, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4623, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3974, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4654, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4502, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4347, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3912, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4412, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4160, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4545, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4271, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5128, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5236, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4960, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4687, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4834, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4875, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4182, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5108, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4419, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4315, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4682, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4261, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4450, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4572, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4866, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4578, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4506, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4928, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 59/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4722, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4603, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4774, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5042, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5103, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4689, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4733, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4717, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4754, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5083, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4766, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4629, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3978, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4442, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4789, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4994, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4409, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4478, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4408, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4743, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4859, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4791, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5007, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4258, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4495, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4622, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4517, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5022, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4842, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5161, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4708, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4731, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4412, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4813, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4510, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4489, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4813, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4665, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3997, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4514, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4509, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4232, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4464, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5239, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4718, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5049, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4508, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4928, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5329, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4609, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4515, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4482, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5140, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4546, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4462, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 61/300 --- train mae: 0.795 val mae: 0.781
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4597, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5024, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4857, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4744, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5570, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5073, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4528, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4083, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4757, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4499, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4918, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4569, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4586, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5090, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5021, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4852, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4530, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4693, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4713, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4563, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4665, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4503, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4354, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4555, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4497, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5438, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5146, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4283, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3892, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4119, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4864, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4245, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4583, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4565, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4806, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4544, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4721, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4457, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4385, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5018, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5057, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4961, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4485, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5077, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4585, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4625, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4671, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4998, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4529, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4613, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4820, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5368, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4242, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([512, 1, 256])) that is different to the input size (torch.Size([512, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MseLossBackward0>)
/home/zd/anaconda3/envs/coor/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([475, 1, 256])) that is different to the input size (torch.Size([475, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MseLossBackward0>)
nohup: ignoring input
Property "jarvis_e_form" selected for training
model_name:  jarvis_e_form_struPred

Model architecture: out_dims, d_model, N, heads
256, 512, 3, 4
Running on compute device: cuda:0
Model size: 12381700 parameters

Generating EDM:   0%|          | 0/28635 [00:00<?, ?formulae/s]Generating EDM:  37%|███▋      | 10548/28635 [00:00<00:00, 105463.25formulae/s]Generating EDM:  76%|███████▌  | 21653/28635 [00:00<00:00, 108743.17formulae/s]Generating EDM: 100%|██████████| 28635/28635 [00:00<00:00, 108853.95formulae/s]
loading data with up to 7 elements in the formula
training with batchsize 512 (2**9.000)
Generating EDM:   0%|          | 0/3182 [00:00<?, ?formulae/s]Generating EDM: 100%|██████████| 3182/3182 [00:00<00:00, 137433.20formulae/s]
loading data with up to 7 elements in the formula
stepping every 56 training passes, cycling lr every 1 epochs
checkin at 2 epochs to match lr scheduler
tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6822, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6971, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6019, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5918, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5796, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4848, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4895, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(0.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4856, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.3045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.5871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4073, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.3920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.5362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3872, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.7394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3796, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.1933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3629, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.6070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.8628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4019, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.8910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3091, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.3609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3082, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(1.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2689, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.1470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2900, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.3746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2980, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2577, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.3046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2816, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.2068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2985, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 0/300 --- train mae: 3.14 val mae: 3.05
tensor(2.8140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2114, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1914, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2101, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1811, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.2710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1976, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1812, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1840, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1979, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1736, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.3846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1807, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1778, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1759, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1680, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1761, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1923, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1547, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1788, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1773, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1828, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1586, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1573, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1574, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1485, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1553, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1556, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 1/300 --- train mae: 3.1 val mae: 3.04
tensor(2.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1567, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1586, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1674, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1434, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1496, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1636, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1565, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1630, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1639, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1769, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1716, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1444, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1076, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1108, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1069, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1076, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1029, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1027, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0925, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0919, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0986, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0928, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1080, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0935, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1015, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1034, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1060, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0985, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0912, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 3 failed to improve.
Discarded: 1/150 weight updates ♻🗑️
Epoch: 3/300 --- train mae: 3.17 val mae: 3.1
tensor(2.8227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0903, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0945, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1059, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0927, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0958, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0983, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1028, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0896, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1015, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0931, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0927, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0918, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1016, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0892, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1071, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0955, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0938, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0852, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1021, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1034, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1075, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0861, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.6590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.2129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1029, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1018, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1042, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0955, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1046, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1033, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0935, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0907, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0938, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1069, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0896, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0985, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0747, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0941, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1086, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0861, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch: 5/300 --- train mae: 3.2 val mae: 3.12
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0927, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0757, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0978, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0944, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0697, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0693, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0897, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0759, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0943, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0909, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1047, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0755, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1049, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1054, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1032, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0757, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0922, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1063, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0881, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0811, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1035, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.6122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0922, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0906, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0957, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0951, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0918, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0920, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0868, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0929, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0745, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0723, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0801, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0891, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0939, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0713, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0914, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0682, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0739, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0618, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0905, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0733, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0735, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0620, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 7 failed to improve.
Discarded: 2/150 weight updates ♻🗑️
Epoch: 7/300 --- train mae: 3.27 val mae: 3.19
tensor(2.9559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0702, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0664, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0656, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0893, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0606, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0914, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0916, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0763, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0699, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0787, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0650, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0728, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0631, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0707, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0880, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0887, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0642, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0731, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0681, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0838, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.5976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0945, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.4154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0931, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0898, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0676, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0662, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0656, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0651, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0620, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0591, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0560, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 9 failed to improve.
Discarded: 3/150 weight updates ♻🗑️
Epoch: 9/300 --- train mae: 3.2 val mae: 3.13
tensor(3.0715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0626, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0550, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0655, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0734, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0676, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0610, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0691, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0684, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0895, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0620, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0735, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0674, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0912, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0714, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0768, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1052, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0676, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0735, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0655, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0581, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0698, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0569, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0699, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0704, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0530, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0568, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0646, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0651, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0698, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0692, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0597, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0629, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 11 failed to improve.
Discarded: 4/150 weight updates ♻🗑️
Epoch: 11/300 --- train mae: 3.22 val mae: 3.14
tensor(2.9932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0640, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0890, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0508, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0595, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0674, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0569, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0607, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0939, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0682, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0686, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0637, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0565, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0606, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0570, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0698, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0641, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0732, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0619, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0694, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0722, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0708, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0663, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0645, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0642, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0611, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0503, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0499, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0525, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0699, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 13 failed to improve.
Discarded: 5/150 weight updates ♻🗑️
Epoch: 13/300 --- train mae: 3.24 val mae: 3.16
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0543, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0528, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0598, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0545, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0642, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0609, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0529, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0586, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0525, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0629, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0788, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0693, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0580, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0630, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0597, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0539, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0748, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0577, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0554, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0687, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0593, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0733, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 15 failed to improve.
Discarded: 6/150 weight updates ♻🗑️
Epoch: 15/300 --- train mae: 3.23 val mae: 3.14
tensor(2.9648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0522, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0503, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0847, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0658, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0582, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0535, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0578, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0716, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0669, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0654, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0710, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0634, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0698, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0603, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0589, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0627, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0530, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 17 failed to improve.
Discarded: 7/150 weight updates ♻🗑️
Epoch: 17/300 --- train mae: 3.26 val mae: 3.18
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0569, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0543, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0560, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0442, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0648, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0503, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0565, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0724, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0693, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0713, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0525, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0515, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0544, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0656, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0614, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 19 failed to improve.
Discarded: 8/150 weight updates ♻🗑️
Epoch: 19/300 --- train mae: 3.2 val mae: 3.12
tensor(2.9208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0562, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0515, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0596, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0590, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0578, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0579, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0525, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0596, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0508, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0508, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0532, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0545, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 21 failed to improve.
Discarded: 9/150 weight updates ♻🗑️
Epoch: 21/300 --- train mae: 3.24 val mae: 3.17
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0442, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0597, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0482, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0557, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0667, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0515, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 23 failed to improve.
Discarded: 10/150 weight updates ♻🗑️
Epoch: 23/300 --- train mae: 3.22 val mae: 3.14
tensor(2.8654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0431, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0499, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0573, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0492, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0431, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 25 failed to improve.
Discarded: 11/150 weight updates ♻🗑️
Epoch: 25/300 --- train mae: 3.23 val mae: 3.15
tensor(2.8340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0568, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0555, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 27 failed to improve.
Discarded: 12/150 weight updates ♻🗑️
Epoch: 27/300 --- train mae: 3.25 val mae: 3.17
tensor(3.0343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0505, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0442, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 29 failed to improve.
Discarded: 13/150 weight updates ♻🗑️
Epoch: 29/300 --- train mae: 3.24 val mae: 3.15
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 31 failed to improve.
Discarded: 14/150 weight updates ♻🗑️
Epoch: 31/300 --- train mae: 3.27 val mae: 3.19
tensor(3.2678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0509, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 33 failed to improve.
Discarded: 15/150 weight updates ♻🗑️
Epoch: 33/300 --- train mae: 3.25 val mae: 3.17
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0597, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0541, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 35 failed to improve.
Discarded: 16/150 weight updates ♻🗑️
Epoch: 35/300 --- train mae: 3.24 val mae: 3.15
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0511, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 37 failed to improve.
Discarded: 17/150 weight updates ♻🗑️
Epoch: 37/300 --- train mae: 3.26 val mae: 3.17
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0523, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0537, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 39 failed to improve.
Discarded: 18/150 weight updates ♻🗑️
Epoch: 39/300 --- train mae: 3.22 val mae: 3.13
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 41 failed to improve.
Discarded: 19/150 weight updates ♻🗑️
Epoch: 41/300 --- train mae: 3.25 val mae: 3.17
tensor(2.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 43 failed to improve.
Discarded: 20/150 weight updates ♻🗑️
Epoch: 43/300 --- train mae: 3.24 val mae: 3.15
tensor(2.9361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 45 failed to improve.
Discarded: 21/150 weight updates ♻🗑️
Epoch: 45/300 --- train mae: 3.25 val mae: 3.16
tensor(2.8724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 47 failed to improve.
Discarded: 22/150 weight updates ♻🗑️
Epoch: 47/300 --- train mae: 3.24 val mae: 3.16
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0396, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0363, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 49 failed to improve.
Discarded: 23/150 weight updates ♻🗑️
Epoch: 49/300 --- train mae: 3.25 val mae: 3.17
tensor(3.1881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 51 failed to improve.
Discarded: 24/150 weight updates ♻🗑️
Epoch: 51/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 53 failed to improve.
Discarded: 25/150 weight updates ♻🗑️
Epoch: 53/300 --- train mae: 3.23 val mae: 3.14
tensor(2.8796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 55 failed to improve.
Discarded: 26/150 weight updates ♻🗑️
Epoch: 55/300 --- train mae: 3.23 val mae: 3.14
tensor(3.1040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0375, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 57 failed to improve.
Discarded: 27/150 weight updates ♻🗑️
Epoch: 57/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 59 failed to improve.
Discarded: 28/150 weight updates ♻🗑️
Epoch: 59/300 --- train mae: 3.23 val mae: 3.14
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 61 failed to improve.
Discarded: 29/150 weight updates ♻🗑️
Epoch: 61/300 --- train mae: 3.24 val mae: 3.15
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 63 failed to improve.
Discarded: 30/150 weight updates ♻🗑️
Epoch: 63/300 --- train mae: 3.24 val mae: 3.15
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 65 failed to improve.
Discarded: 31/150 weight updates ♻🗑️
Epoch: 65/300 --- train mae: 3.24 val mae: 3.16
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 67 failed to improve.
Discarded: 32/150 weight updates ♻🗑️
Epoch: 67/300 --- train mae: 3.22 val mae: 3.13
tensor(2.9323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 69 failed to improve.
Discarded: 33/150 weight updates ♻🗑️
Epoch: 69/300 --- train mae: 3.25 val mae: 3.16
tensor(2.7739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 71 failed to improve.
Discarded: 34/150 weight updates ♻🗑️
Epoch: 71/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 73 failed to improve.
Discarded: 35/150 weight updates ♻🗑️
Epoch: 73/300 --- train mae: 3.24 val mae: 3.15
tensor(2.9745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 75 failed to improve.
Discarded: 36/150 weight updates ♻🗑️
Epoch: 75/300 --- train mae: 3.24 val mae: 3.16
tensor(2.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 77 failed to improve.
Discarded: 37/150 weight updates ♻🗑️
Epoch: 77/300 --- train mae: 3.24 val mae: 3.14
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 79 failed to improve.
Discarded: 38/150 weight updates ♻🗑️
Epoch: 79/300 --- train mae: 3.24 val mae: 3.15
tensor(2.8902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 81 failed to improve.
Discarded: 39/150 weight updates ♻🗑️
Epoch: 81/300 --- train mae: 3.23 val mae: 3.14
tensor(2.8631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 83 failed to improve.
Discarded: 40/150 weight updates ♻🗑️
Epoch: 83/300 --- train mae: 3.24 val mae: 3.14
tensor(2.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 85 failed to improve.
Discarded: 41/150 weight updates ♻🗑️
Epoch: 85/300 --- train mae: 3.23 val mae: 3.13
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0493, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 87 failed to improve.
Discarded: 42/150 weight updates ♻🗑️
Epoch: 87/300 --- train mae: 3.23 val mae: 3.14
tensor(3.2248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0349, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 89 failed to improve.
Discarded: 43/150 weight updates ♻🗑️
Epoch: 89/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 91 failed to improve.
Discarded: 44/150 weight updates ♻🗑️
Epoch: 91/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 93 failed to improve.
Discarded: 45/150 weight updates ♻🗑️
Epoch: 93/300 --- train mae: 3.24 val mae: 3.15
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 95 failed to improve.
Discarded: 46/150 weight updates ♻🗑️
Epoch: 95/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 97 failed to improve.
Discarded: 47/150 weight updates ♻🗑️
Epoch: 97/300 --- train mae: 3.25 val mae: 3.16
tensor(2.9591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 99 failed to improve.
Discarded: 48/150 weight updates ♻🗑️
Epoch: 99/300 --- train mae: 3.22 val mae: 3.13
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 101 failed to improve.
Discarded: 49/150 weight updates ♻🗑️
Epoch: 101/300 --- train mae: 3.24 val mae: 3.14
tensor(2.8320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 103 failed to improve.
Discarded: 50/150 weight updates ♻🗑️
Epoch: 103/300 --- train mae: 3.23 val mae: 3.14
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 105 failed to improve.
Discarded: 51/150 weight updates ♻🗑️
Epoch: 105/300 --- train mae: 3.24 val mae: 3.14
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 107 failed to improve.
Discarded: 52/150 weight updates ♻🗑️
Epoch: 107/300 --- train mae: 3.24 val mae: 3.14
tensor(2.9742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 109 failed to improve.
Discarded: 53/150 weight updates ♻🗑️
Epoch: 109/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 111 failed to improve.
Discarded: 54/150 weight updates ♻🗑️
Epoch: 111/300 --- train mae: 3.22 val mae: 3.13
tensor(3.0653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 113 failed to improve.
Discarded: 55/150 weight updates ♻🗑️
Epoch: 113/300 --- train mae: 3.23 val mae: 3.14
tensor(2.9172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 115 failed to improve.
Discarded: 56/150 weight updates ♻🗑️
Epoch: 115/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 117 failed to improve.
Discarded: 57/150 weight updates ♻🗑️
Epoch: 117/300 --- train mae: 3.24 val mae: 3.14
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 119 failed to improve.
Discarded: 58/150 weight updates ♻🗑️
Epoch: 119/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 121 failed to improve.
Discarded: 59/150 weight updates ♻🗑️
Epoch: 121/300 --- train mae: 3.22 val mae: 3.12
tensor(2.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 123 failed to improve.
Discarded: 60/150 weight updates ♻🗑️
Epoch: 123/300 --- train mae: 3.24 val mae: 3.14
tensor(3.1821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 125 failed to improve.
Discarded: 61/150 weight updates ♻🗑️
Epoch: 125/300 --- train mae: 3.23 val mae: 3.14
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 127 failed to improve.
Discarded: 62/150 weight updates ♻🗑️
Epoch: 127/300 --- train mae: 3.24 val mae: 3.14
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 129 failed to improve.
Discarded: 63/150 weight updates ♻🗑️
Epoch: 129/300 --- train mae: 3.23 val mae: 3.14
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 131 failed to improve.
Discarded: 64/150 weight updates ♻🗑️
Epoch: 131/300 --- train mae: 3.22 val mae: 3.13
tensor(3.1009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 133 failed to improve.
Discarded: 65/150 weight updates ♻🗑️
Epoch: 133/300 --- train mae: 3.22 val mae: 3.12
tensor(2.9589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 135 failed to improve.
Discarded: 66/150 weight updates ♻🗑️
Epoch: 135/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 137 failed to improve.
Discarded: 67/150 weight updates ♻🗑️
Epoch: 137/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 139 failed to improve.
Discarded: 68/150 weight updates ♻🗑️
Epoch: 139/300 --- train mae: 3.22 val mae: 3.13
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 141 failed to improve.
Discarded: 69/150 weight updates ♻🗑️
Epoch: 141/300 --- train mae: 3.23 val mae: 3.14
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 143 failed to improve.
Discarded: 70/150 weight updates ♻🗑️
Epoch: 143/300 --- train mae: 3.24 val mae: 3.14
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 145 failed to improve.
Discarded: 71/150 weight updates ♻🗑️
Epoch: 145/300 --- train mae: 3.24 val mae: 3.14
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 147 failed to improve.
Discarded: 72/150 weight updates ♻🗑️
Epoch: 147/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 149 failed to improve.
Discarded: 73/150 weight updates ♻🗑️
Epoch: 149/300 --- train mae: 3.23 val mae: 3.13
tensor(2.7931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 151 failed to improve.
Discarded: 74/150 weight updates ♻🗑️
Epoch: 151/300 --- train mae: 3.24 val mae: 3.14
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 153 failed to improve.
Discarded: 75/150 weight updates ♻🗑️
Epoch: 153/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 155 failed to improve.
Discarded: 76/150 weight updates ♻🗑️
Epoch: 155/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 157 failed to improve.
Discarded: 77/150 weight updates ♻🗑️
Epoch: 157/300 --- train mae: 3.24 val mae: 3.13
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 159 failed to improve.
Discarded: 78/150 weight updates ♻🗑️
Epoch: 159/300 --- train mae: 3.24 val mae: 3.13
tensor(2.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 161 failed to improve.
Discarded: 79/150 weight updates ♻🗑️
Epoch: 161/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 163 failed to improve.
Discarded: 80/150 weight updates ♻🗑️
Epoch: 163/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 165 failed to improve.
Discarded: 81/150 weight updates ♻🗑️
Epoch: 165/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 167 failed to improve.
Discarded: 82/150 weight updates ♻🗑️
Epoch: 167/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.5124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 169 failed to improve.
Discarded: 83/150 weight updates ♻🗑️
Epoch: 169/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 171 failed to improve.
Discarded: 84/150 weight updates ♻🗑️
Epoch: 171/300 --- train mae: 3.23 val mae: 3.13
tensor(2.6843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 173 failed to improve.
Discarded: 85/150 weight updates ♻🗑️
Epoch: 173/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 175 failed to improve.
Discarded: 86/150 weight updates ♻🗑️
Epoch: 175/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 177 failed to improve.
Discarded: 87/150 weight updates ♻🗑️
Epoch: 177/300 --- train mae: 3.22 val mae: 3.12
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 179 failed to improve.
Discarded: 88/150 weight updates ♻🗑️
Epoch: 179/300 --- train mae: 3.22 val mae: 3.12
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 181 failed to improve.
Discarded: 89/150 weight updates ♻🗑️
Epoch: 181/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 183 failed to improve.
Discarded: 90/150 weight updates ♻🗑️
Epoch: 183/300 --- train mae: 3.22 val mae: 3.13
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 185 failed to improve.
Discarded: 91/150 weight updates ♻🗑️
Epoch: 185/300 --- train mae: 3.22 val mae: 3.13
tensor(2.9575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 187 failed to improve.
Discarded: 92/150 weight updates ♻🗑️
Epoch: 187/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 189 failed to improve.
Discarded: 93/150 weight updates ♻🗑️
Epoch: 189/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 191 failed to improve.
Discarded: 94/150 weight updates ♻🗑️
Epoch: 191/300 --- train mae: 3.23 val mae: 3.14
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 193 failed to improve.
Discarded: 95/150 weight updates ♻🗑️
Epoch: 193/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.5840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 195 failed to improve.
Discarded: 96/150 weight updates ♻🗑️
Epoch: 195/300 --- train mae: 3.23 val mae: 3.14
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 197 failed to improve.
Discarded: 97/150 weight updates ♻🗑️
Epoch: 197/300 --- train mae: 3.22 val mae: 3.13
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 199 failed to improve.
Discarded: 98/150 weight updates ♻🗑️
Epoch: 199/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 201 failed to improve.
Discarded: 99/150 weight updates ♻🗑️
Epoch: 201/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 203 failed to improve.
Discarded: 100/150 weight updates ♻🗑️
Epoch: 203/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 205 failed to improve.
Discarded: 101/150 weight updates ♻🗑️
Epoch: 205/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9758, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 207 failed to improve.
Discarded: 102/150 weight updates ♻🗑️
Epoch: 207/300 --- train mae: 3.23 val mae: 3.12
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0369, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 209 failed to improve.
Discarded: 103/150 weight updates ♻🗑️
Epoch: 209/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 211 failed to improve.
Discarded: 104/150 weight updates ♻🗑️
Epoch: 211/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 213 failed to improve.
Discarded: 105/150 weight updates ♻🗑️
Epoch: 213/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 215 failed to improve.
Discarded: 106/150 weight updates ♻🗑️
Epoch: 215/300 --- train mae: 3.23 val mae: 3.13
tensor(2.8832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 217 failed to improve.
Discarded: 107/150 weight updates ♻🗑️
Epoch: 217/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 219 failed to improve.
Discarded: 108/150 weight updates ♻🗑️
Epoch: 219/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 221 failed to improve.
Discarded: 109/150 weight updates ♻🗑️
Epoch: 221/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.4216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 223 failed to improve.
Discarded: 110/150 weight updates ♻🗑️
Epoch: 223/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 225 failed to improve.
Discarded: 111/150 weight updates ♻🗑️
Epoch: 225/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 227 failed to improve.
Discarded: 112/150 weight updates ♻🗑️
Epoch: 227/300 --- train mae: 3.22 val mae: 3.13
tensor(3.2487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 229 failed to improve.
Discarded: 113/150 weight updates ♻🗑️
Epoch: 229/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 231 failed to improve.
Discarded: 114/150 weight updates ♻🗑️
Epoch: 231/300 --- train mae: 3.22 val mae: 3.13
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 233 failed to improve.
Discarded: 115/150 weight updates ♻🗑️
Epoch: 233/300 --- train mae: 3.22 val mae: 3.12
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 235 failed to improve.
Discarded: 116/150 weight updates ♻🗑️
Epoch: 235/300 --- train mae: 3.22 val mae: 3.12
tensor(3.1444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 237 failed to improve.
Discarded: 117/150 weight updates ♻🗑️
Epoch: 237/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 239 failed to improve.
Discarded: 118/150 weight updates ♻🗑️
Epoch: 239/300 --- train mae: 3.22 val mae: 3.12
tensor(2.8900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 241 failed to improve.
Discarded: 119/150 weight updates ♻🗑️
Epoch: 241/300 --- train mae: 3.21 val mae: 3.12
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 243 failed to improve.
Discarded: 120/150 weight updates ♻🗑️
Epoch: 243/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 245 failed to improve.
Discarded: 121/150 weight updates ♻🗑️
Epoch: 245/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 247 failed to improve.
Discarded: 122/150 weight updates ♻🗑️
Epoch: 247/300 --- train mae: 3.22 val mae: 3.14
tensor(3.1044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0357, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 249 failed to improve.
Discarded: 123/150 weight updates ♻🗑️
Epoch: 249/300 --- train mae: 3.22 val mae: 3.13
tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 251 failed to improve.
Discarded: 124/150 weight updates ♻🗑️
Epoch: 251/300 --- train mae: 3.22 val mae: 3.12
tensor(2.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 253 failed to improve.
Discarded: 125/150 weight updates ♻🗑️
Epoch: 253/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 255 failed to improve.
Discarded: 126/150 weight updates ♻🗑️
Epoch: 255/300 --- train mae: 3.23 val mae: 3.12
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 257 failed to improve.
Discarded: 127/150 weight updates ♻🗑️
Epoch: 257/300 --- train mae: 3.22 val mae: 3.12
tensor(3.1132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 259 failed to improve.
Discarded: 128/150 weight updates ♻🗑️
Epoch: 259/300 --- train mae: 3.24 val mae: 3.14
tensor(2.9982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1204, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 261 failed to improve.
Discarded: 129/150 weight updates ♻🗑️
Epoch: 261/300 --- train mae: 3.22 val mae: 3.12
tensor(2.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0341, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 263 failed to improve.
Discarded: 130/150 weight updates ♻🗑️
Epoch: 263/300 --- train mae: 3.22 val mae: 3.12
tensor(3.1012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 265 failed to improve.
Discarded: 131/150 weight updates ♻🗑️
Epoch: 265/300 --- train mae: 3.23 val mae: 3.14
tensor(2.9512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 267 failed to improve.
Discarded: 132/150 weight updates ♻🗑️
Epoch: 267/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8415, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 269 failed to improve.
Discarded: 133/150 weight updates ♻🗑️
Epoch: 269/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9842, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 271 failed to improve.
Discarded: 134/150 weight updates ♻🗑️
Epoch: 271/300 --- train mae: 3.22 val mae: 3.12
tensor(3.1071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 273 failed to improve.
Discarded: 135/150 weight updates ♻🗑️
Epoch: 273/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1529, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8864, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 275 failed to improve.
Discarded: 136/150 weight updates ♻🗑️
Epoch: 275/300 --- train mae: 3.22 val mae: 3.12
tensor(3.2462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0567, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0947, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 277 failed to improve.
Discarded: 137/150 weight updates ♻🗑️
Epoch: 277/300 --- train mae: 3.22 val mae: 3.12
tensor(2.9753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0714, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 279 failed to improve.
Discarded: 138/150 weight updates ♻🗑️
Epoch: 279/300 --- train mae: 3.23 val mae: 3.13
tensor(2.9746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8568, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1322, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 281 failed to improve.
Discarded: 139/150 weight updates ♻🗑️
Epoch: 281/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0739, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8767, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 283 failed to improve.
Discarded: 140/150 weight updates ♻🗑️
Epoch: 283/300 --- train mae: 3.23 val mae: 3.13
tensor(3.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2301, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 285 failed to improve.
Discarded: 141/150 weight updates ♻🗑️
Epoch: 285/300 --- train mae: 3.23 val mae: 3.12
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9761, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0922, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 287 failed to improve.
Discarded: 142/150 weight updates ♻🗑️
Epoch: 287/300 --- train mae: 3.22 val mae: 3.12
tensor(2.9007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9925, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0125, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1366, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 289 failed to improve.
Discarded: 143/150 weight updates ♻🗑️
Epoch: 289/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3804, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 291 failed to improve.
Discarded: 144/150 weight updates ♻🗑️
Epoch: 291/300 --- train mae: 3.21 val mae: 3.11
tensor(3.2930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0984, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.6633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0791, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1798, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0147, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9897, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7913, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 293 failed to improve.
Discarded: 145/150 weight updates ♻🗑️
Epoch: 293/300 --- train mae: 3.22 val mae: 3.12
tensor(3.0774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0410, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 295 failed to improve.
Discarded: 146/150 weight updates ♻🗑️
Epoch: 295/300 --- train mae: 3.23 val mae: 3.13
tensor(3.1046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1088, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0113, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2293, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 297 failed to improve.
Discarded: 147/150 weight updates ♻🗑️
Epoch: 297/300 --- train mae: 3.22 val mae: 3.12
tensor(2.8638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0112, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0730, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0976, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0136, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0148, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.7191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0129, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.3003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.2575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(2.9275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)
tensor(3.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)
Epoch 299 failed to improve.
Discarded: 148/150 weight updates ♻🗑️
Epoch: 299/300 --- train mae: 3.23 val mae: 3.12
Saving checkpoint (jarvis_e_form_struPred_epoch299) to /home/zd/zd/teaching_net/CrabNet/predict_structurEmbedding/jarvis_e_form/models/jarvis_e_form_struPred_epoch299.pth
Saving network (jarvis_e_form_struPred) to /home/zd/zd/teaching_net/CrabNet/predict_structurEmbedding/jarvis_e_form/models/jarvis_e_form_struPred.pth
=====================================================
                    jarvis_e_form                    
=====================================================
calculating train mae
jarvis_e_form_struPred /home/zd/zd/teaching_net/CrabNet/predict_structurEmbedding/jarvis_e_form/models
loading data with up to 7 elements in the formula
jarvis_e_form mae: 2.54
-----------------------------------------------------
calculating val mae
jarvis_e_form_struPred /home/zd/zd/teaching_net/CrabNet/predict_structurEmbedding/jarvis_e_form/models
loading data with up to 6 elements in the formula
jarvis_e_form mae: 2.49
-----------------------------------------------------
calculating test mae
jarvis_e_form_struPred /home/zd/zd/teaching_net/CrabNet/predict_structurEmbedding/jarvis_e_form/models
loading data with up to 7 elements in the formula
jarvis_e_form mae: 2.54
=====================================================
